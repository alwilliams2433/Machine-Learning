{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Implementation with Bigram Data Representation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"hw2data_1/reviews_tr.csv\"\n",
    "df_train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Representation: Bigram\n",
    "# Use hashmap to compress the data\n",
    "def data_compression(df_train):\n",
    "    list_dict = []  # Contains training examples compressed with hashmap\n",
    "    vocabulary_dict = {} # Contains the position to reconstruct the feature vector\n",
    "    for index, row in df_train.iterrows():\n",
    "        new_dict = {}\n",
    "        words = row['text'] + \"\"\n",
    "        words = words.split()\n",
    "        \n",
    "        \n",
    "        for i in range(len(words) - 1):\n",
    "            key = words[i] + \" \" + words[i + 1]\n",
    "            if key in new_dict:\n",
    "                new_dict[key] += 1\n",
    "            else:\n",
    "                new_dict[key] = 1\n",
    "\n",
    "        if(row['label'] == 1):  # Attach the label\n",
    "            new_dict['*label*'] = 1\n",
    "        else: new_dict['*label*'] = -1\n",
    "\n",
    "        new_dict['*const*'] = 1   # Lifting\n",
    "        list_dict.append(new_dict)\n",
    "\n",
    "    \n",
    "    return list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_bigram(list_dict):\n",
    "    w = {} \n",
    "    \n",
    "    # First pass\n",
    "    random.shuffle(list_dict)\n",
    "    for x in list_dict:\n",
    "        dot_product = 0\n",
    "        label = x['*label*']\n",
    "        for key, value in x.items():\n",
    "            if key != '*label*':\n",
    "                if key in w:\n",
    "                    dot_product += w[key] * x[key]\n",
    "        \n",
    "        if dot_product * label <= 0:           \n",
    "            for key, value in x.items():\n",
    "                if key != '*label*':\n",
    "                    if key in w:\n",
    "                        w[key] += label * x[key]\n",
    "                    else: w[key] = label * x[key]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 153.72502398490906 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "list_dict = data_compression(df_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 113.894287109375 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "w = train_bigram(list_dict)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('three stars', -79), ('a ok', -74), ('two stars', -66), ('2 stars', -57), ('3 stars', -57), ('very disappointed', -45), ('the worst', -44), ('very bland', -43), ('not impressed', -43), ('not worth', -40), ('more stars', -40), ('so salty', -40), ('just average', -40), ('meh i', -40), ('very disappointing', -39), ('mediocre food', -39), ('food poisoning', -38), ('over priced', -38), ('a joke', -38), ('was awful', -37)]\n"
     ]
    }
   ],
   "source": [
    "# Top20 positive words\n",
    "print(sorted(w.items(), key=lambda x: x[1], reverse = False)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('five stars', 67), ('four stars', 52), ('4 because', 45), ('not disappointed', 44), ('round up', 44), ('fifth star', 40), ('only negative', 38), ('fries diet', 38), ('5th star', 38), ('coke double', 38), ('not disappoint', 37), ('rounded up', 37), ('my new', 36), ('star off', 36), ('t disappointed', 35), ('onions fries', 35), ('5 but', 32), ('to 4', 32), ('was phenomenal', 31), ('very pleased', 31)]\n"
     ]
    }
   ],
   "source": [
    "# Top20 negative words\n",
    "print(sorted(w.items(), key=lambda x: x[1], reverse = True)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2 = \"hw2data_1/reviews_te.csv\"\n",
    "df_test = pd.read_csv(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_bigram(df_test, w):\n",
    "    dict_list_test = data_compression(df_test)\n",
    "    count = 0\n",
    "    wrong = 0\n",
    "    for dictionary in dict_list_test:\n",
    "        count += 1\n",
    "        dot_product = 0\n",
    "        label = dictionary['*label*']\n",
    "        for key, value in dictionary.items():\n",
    "            if key in w and key != '*label*':\n",
    "                dot_product += w[key] * dictionary[key]\n",
    "        if dot_product * label <= 0: wrong += 1 \n",
    "    return (count - wrong) / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.901897\n",
      "--- 279.6965320110321 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(test_bigram(df_test, w))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
