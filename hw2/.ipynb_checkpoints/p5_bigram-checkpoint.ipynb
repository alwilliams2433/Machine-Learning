{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Implementation with Bigram Data Representation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "path = \"hw2data_1/reviews_tr.csv\"\n",
    "df_train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load testing data\n",
    "path2 = \"hw2data_1/reviews_te.csv\"\n",
    "df_test = pd.read_csv(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Representation: Bigram\n",
    "# Use hashmap to compress the data\n",
    "def data_compression(df_train):\n",
    "    list_dict = []  # Contains training examples compressed with hashmap\n",
    "    for index, row in df_train.iterrows():\n",
    "        new_dict = {}\n",
    "        words = row['text'] + \"\"\n",
    "        words = words.split()\n",
    "        \n",
    "        for i in range(len(words) - 1):\n",
    "            key = words[i] + \" \" + words[i + 1] # Use two words as key\n",
    "            if key in new_dict:\n",
    "                new_dict[key] += 1\n",
    "            else:\n",
    "                new_dict[key] = 1\n",
    "\n",
    "        if(row['label'] == 1):  # Attach the label\n",
    "            new_dict['*label*'] = 1\n",
    "        else: new_dict['*label*'] = -1\n",
    "\n",
    "        new_dict['*const*'] = 1   # Lifting\n",
    "        list_dict.append(new_dict)\n",
    "\n",
    "    \n",
    "    return list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Online-batch perceptron implementation\n",
    "def train_bigram(list_dict):\n",
    "    w = {} \n",
    "    \n",
    "    random.shuffle(list_dict)\n",
    "    for x in list_dict:\n",
    "        dot_product = 0\n",
    "        label = x['*label*']\n",
    "        for key, value in x.items():\n",
    "            if key != '*label*':\n",
    "                if key in w:\n",
    "                    dot_product += w[key] * x[key]\n",
    "        \n",
    "        if dot_product * label <= 0:           \n",
    "            for key, value in x.items():\n",
    "                if key != '*label*':\n",
    "                    if key in w:\n",
    "                        w[key] += label * x[key]\n",
    "                    else: w[key] = label * x[key]\n",
    "                        \n",
    "    random.shuffle(list_dict)\n",
    "    w_ret = dict(w) # Initilize w_ret\n",
    "    for x in list_dict:\n",
    "        dot_product = 0\n",
    "        label = x['*label*']\n",
    "        for key, value in x.items():\n",
    "            if key != '*label*':\n",
    "                if key in w:\n",
    "                    dot_product += w[key] * x[key]\n",
    "           \n",
    "        if dot_product * label <= 0:\n",
    "            for key, value in x.items():\n",
    "                if key != '*label*':\n",
    "                    if key in w:\n",
    "                        w[key] += label * x[key]\n",
    "                    else: w[key] = label * x[key]\n",
    "        \n",
    "        # Update w_ret\n",
    "        for key, value in w.items():\n",
    "            if key in w_ret:\n",
    "                w_ret[key] += value\n",
    "            else:\n",
    "                w_ret[key] = value\n",
    "                \n",
    "                \n",
    "    # Calculate weighted weight vector\n",
    "    length = len(list_dict) + 1\n",
    "    for key, value in w_ret.items():\n",
    "        w_ret[key] /= length            \n",
    "    return w_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test classifier on a give testing set\n",
    "def test_bigram(dict_list_test, w):\n",
    "    count = 0\n",
    "    wrong = 0\n",
    "    for dictionary in dict_list_test:\n",
    "        count += 1\n",
    "        dot_product = 0\n",
    "        label = dictionary['*label*']\n",
    "        for key, value in dictionary.items():\n",
    "            if key in w and key != '*label*':\n",
    "                dot_product += w[key] * dictionary[key]\n",
    "        if dot_product * label <= 0: wrong += 1 \n",
    "    return (count - wrong) / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 143.66006231307983 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "list_dict = data_compression(df_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluating the performance of the classifier with different training sizes: 10%, 20%, ... ,100%\n",
    "def test(df_test, list_dict):\n",
    "    dict_list_test = data_compression(df_test)\n",
    "    w_list = []\n",
    "    accuracy_list = []\n",
    "    for i in range(10):\n",
    "        list_dict_training = list_dict[:int(len(list_dict) * 0.1 * (i + 1))]\n",
    "        w = train_bigram(list_dict_training)\n",
    "        w_list.append(w)\n",
    "        print('Training size: ', (i + 1) * 10, '%', end='')\n",
    "        \n",
    "        accuracy = test_bigram(dict_list_test, w)\n",
    "        accuracy_list.append(accuracy)\n",
    "        print('  Accuracy: ', accuracy)\n",
    "        print()\n",
    "        \n",
    "    return w_list, accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  10 %  Accuracy:  0.8495511086398311\n",
      "\n",
      "Training size:  20 %  Accuracy:  0.855533202966369\n",
      "\n",
      "Training size:  30 %  Accuracy:  0.8538807079800826\n",
      "\n",
      "Training size:  40 %  Accuracy:  0.8655700014369522\n",
      "\n",
      "Training size:  50 %  Accuracy:  0.8577948407169766\n",
      "\n",
      "Training size:  60 %  Accuracy:  0.8667726679203553\n",
      "\n",
      "Training size:  70 %  Accuracy:  0.8680815439113838\n",
      "\n",
      "Training size:  80 %  Accuracy:  0.8751600952136998\n",
      "\n",
      "Training size:  90 %  Accuracy:  0.8706961720843929\n",
      "\n",
      "Training size:  100 %  Accuracy:  0.8700807817019761\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_list = []\n",
    "accuracy_list = []\n",
    "w_list, accuracy_list = test(df_test, list_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a ok', -71),\n",
       " ('two stars', -68),\n",
       " ('three stars', -66),\n",
       " ('3 stars', -62),\n",
       " ('very disappointed', -51),\n",
       " ('2 stars', -46),\n",
       " ('so disappointed', -46),\n",
       " ('food poisoning', -46),\n",
       " ('not worth', -45),\n",
       " ('the worst', -45),\n",
       " ('never again', -44),\n",
       " ('3 star', -43),\n",
       " ('very disappointing', -43),\n",
       " ('mediocre food', -42),\n",
       " ('an ok', -38),\n",
       " ('2 5', -37),\n",
       " ('more stars', -37),\n",
       " ('not impressed', -36),\n",
       " ('meh i', -36),\n",
       " ('an okay', -35)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top20 positive phrases when training size is 70% (highest accuracy)\n",
    "sorted(w_list[7].items(), key=lambda x: x[1], reverse = False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('five stars', 49),\n",
       " ('not disappointed', 47),\n",
       " ('four stars', 44),\n",
       " ('rib crab', 43),\n",
       " ('4 because', 39),\n",
       " ('round up', 39),\n",
       " ('just perfect', 38),\n",
       " ('never disappointed', 38),\n",
       " ('legs prime', 38),\n",
       " ('this good', 35),\n",
       " ('all delicious', 35),\n",
       " ('only negative', 34),\n",
       " ('was impeccable', 34),\n",
       " ('4 stars', 33),\n",
       " ('5 stars', 33),\n",
       " ('definitely coming', 32),\n",
       " ('you won', 32),\n",
       " ('very pleased', 32),\n",
       " ('new favorite', 31),\n",
       " ('t disappointed', 31)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top20 positive phrases when training size is 70% (highest accuracy)\n",
    "sorted(w_list[7].items(), key=lambda x: x[1], reverse = True)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Training size:  10 %  Accuracy:  0.8495511086398311\n",
    "    Training size:  20 %  Accuracy:  0.855533202966369\n",
    "    Training size:  30 %  Accuracy:  0.8538807079800826\n",
    "    Training size:  40 %  Accuracy:  0.8655700014369522\n",
    "    Training size:  50 %  Accuracy:  0.8577948407169766\n",
    "    Training size:  60 %  Accuracy:  0.8667726679203553\n",
    "    Training size:  70 %  Accuracy:  0.8680815439113838\n",
    "    Training size:  80 %  Accuracy:  0.8751600952136998\n",
    "    Training size:  90 %  Accuracy:  0.8706961720843929\n",
    "    Training size:  100 %  Accuracy:  0.8700807817019761\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 113.894287109375 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "w = train_bigram(list_dict)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('three stars', -79), ('a ok', -74), ('two stars', -66), ('2 stars', -57), ('3 stars', -57), ('very disappointed', -45), ('the worst', -44), ('very bland', -43), ('not impressed', -43), ('not worth', -40), ('more stars', -40), ('so salty', -40), ('just average', -40), ('meh i', -40), ('very disappointing', -39), ('mediocre food', -39), ('food poisoning', -38), ('over priced', -38), ('a joke', -38), ('was awful', -37)]\n"
     ]
    }
   ],
   "source": [
    "# Top20 positive words\n",
    "sorted(w.items(), key=lambda x: x[1], reverse = False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('five stars', 67), ('four stars', 52), ('4 because', 45), ('not disappointed', 44), ('round up', 44), ('fifth star', 40), ('only negative', 38), ('fries diet', 38), ('5th star', 38), ('coke double', 38), ('not disappoint', 37), ('rounded up', 37), ('my new', 36), ('star off', 36), ('t disappointed', 35), ('onions fries', 35), ('5 but', 32), ('to 4', 32), ('was phenomenal', 31), ('very pleased', 31)]\n"
     ]
    }
   ],
   "source": [
    "# Top20 negative words\n",
    "sorted(w.items(), key=lambda x: x[1], reverse = True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.901897\n",
      "--- 279.6965320110321 seconds ---\n"
     ]
    }
   ],
   "source": [
    "dict_list_test = data_compression(df_test)\n",
    "start_time = time.time()\n",
    "print(test_bigram(dict_list_test, w))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
