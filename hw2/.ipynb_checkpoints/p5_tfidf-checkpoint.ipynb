{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Implementation with Tf-idf Data Representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"hw2data_1/reviews_tr.csv\"\n",
    "df_train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Representation: tf-idf\n",
    "# Use hashmap to compress the data\n",
    "def data_compression(df_train):\n",
    "    list_dict = []  # Contains training examples compressed with hashmap\n",
    "\n",
    "    for index, row in df_train.iterrows():\n",
    "        new_dict = {}\n",
    "        words = row['text'] + \"\"\n",
    "        words = words.split()\n",
    "        for word in words:\n",
    "            if word not in stopwords and len(word) < 17: # Stopwords & filter some invalid strings\n",
    "                if word in new_dict:\n",
    "                    new_dict[word] += 1\n",
    "                else:\n",
    "                    new_dict[word] = 1\n",
    "\n",
    "        if(row['label'] == 1):  # Attach the label\n",
    "            new_dict['*label*'] = 1\n",
    "        else: new_dict['*label*'] = -1\n",
    "\n",
    "        new_dict['*const*'] = 1   # Lifting\n",
    "        list_dict.append(new_dict)\n",
    "\n",
    "    return list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_tfidf(list_dict):\n",
    "    w = {} \n",
    "    \n",
    "    # First pass\n",
    "    random.shuffle(list_dict)\n",
    "    for x in list_dict:\n",
    "        dot_product = 0\n",
    "        label = x['*label*']\n",
    "        for key, value in x.items():\n",
    "            if key != '*label*':\n",
    "                if key in w:\n",
    "                    dot_product += w[key] * x[key]\n",
    "        \n",
    "        if dot_product * label <= 0:           \n",
    "            for key, value in x.items():\n",
    "                if key != '*label*':\n",
    "                    if key in w:\n",
    "                        w[key] += label * x[key]\n",
    "                    else: w[key] = label * x[key]\n",
    "     \n",
    "    \n",
    "    # Second pass\n",
    "    random.shuffle(list_dict)\n",
    "    w_ret = dict(w) # Initilize w_ret\n",
    "    for x in list_dict:\n",
    "        dot_product = 0\n",
    "        label = x['*label*']\n",
    "        for key, value in x.items():\n",
    "            if key != '*label*':\n",
    "                if key in w:\n",
    "                    dot_product += w[key] * x[key]\n",
    "           \n",
    "        if dot_product * label <= 0:\n",
    "            for key, value in x.items():\n",
    "                if key != '*label*':\n",
    "                    if key in w:\n",
    "                        w[key] += label * x[key]\n",
    "                    else: w[key] = label * x[key]\n",
    "        \n",
    "        # Update w_ret\n",
    "        for key, value in w.items():\n",
    "            if key in w_ret:\n",
    "                w_ret[key] += value\n",
    "            else:\n",
    "                w_ret[key] = value\n",
    "                \n",
    "    length = len(list_dict) + 1\n",
    "    for key, value in w_ret.items():\n",
    "        w_ret[key] /= length\n",
    "    return w_ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 130.5123209953308 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "list_dict = data_compression(df_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify feature vectors' values based on tf-idf\n",
    "frequency = {}\n",
    "for x in list_dict:\n",
    "    for key, value in x.items():\n",
    "        if key in frequency:\n",
    "            frequency[key] += 1\n",
    "        else:\n",
    "            frequency[key] = 1\n",
    "\n",
    "for x in list_dict:\n",
    "    for key, value in x.items():\n",
    "        if key != '*label*' and key != '*const*':\n",
    "            x[key] = x[key] * math.log((len(list_dict) / frequency[key]), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time --- 167.93792510032654 seconds ---\n"
     ]
    }
   ],
   "source": [
    "list_dict_tmp = list_dict[:int(len(list_dict)*0.03)]\n",
    "start_time = time.time()\n",
    "w = train_tfidf(list_dict_tmp) # Test on a smaller subset\n",
    "print(\"Training time --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lwqb9h3jz9wtk24lr', -143.99999999999997),\n",
       " ('anzq', -143.99999999999997),\n",
       " ('hanoi', -122.79087609044699),\n",
       " ('dima', -122.00875854026675),\n",
       " ('no1dp', -103.91396672279238),\n",
       " ('yasha', -94.07507962915219),\n",
       " ('ok', -92.2389840300337),\n",
       " ('dh', -88.20511975092161),\n",
       " ('pettit', -87.4132690116552),\n",
       " ('cardos', -86.77210593646129),\n",
       " ('worst', -85.24122015310247),\n",
       " ('okay', -83.55269977629658),\n",
       " ('riata', -81.80311309161843),\n",
       " ('prostitute', -80.81470686957579),\n",
       " ('kakuni', -80.81470686957579),\n",
       " ('bland', -79.85562972565918),\n",
       " ('decent', -78.75404962115893),\n",
       " ('mediocre', -78.13549512404944),\n",
       " ('however', -75.44912920375026),\n",
       " ('zak', -73.76335950839965),\n",
       " ('promoters', -73.69981517247945),\n",
       " ('bad', -73.49335809793533),\n",
       " ('violeta', -72.64337162775044),\n",
       " ('vito', -72.25215525032407),\n",
       " ('mudvain', -71.99999999999999)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w.items(), key=lambda x: x[1], reverse = False)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('katz', 223.80468989661645),\n",
       " ('grp', 186.01109951944193),\n",
       " ('kg', 132.48191460990313),\n",
       " ('bola', 122.00875854026675),\n",
       " ('dazzo', 110.40159550823518),\n",
       " ('schwartz', 106.6740854552407),\n",
       " ('biz_photos', 103.44407432183588),\n",
       " ('bertolucci', 98.35114601123315),\n",
       " ('amazing', 97.83743638712194),\n",
       " ('lloll', 97.43477733095793),\n",
       " ('delicious', 95.20046441643834),\n",
       " ('definitely', 94.53852963721539),\n",
       " ('love', 92.59966980288678),\n",
       " ('best', 91.99830062649129),\n",
       " ('sugarbakers', 91.50656890520054),\n",
       " ('www', 91.17673139178257),\n",
       " ('bann', 90.04975600331132),\n",
       " ('http', 79.24328420481059),\n",
       " ('*const*', 78.54784521547845),\n",
       " ('bulgur', 78.15325221094119),\n",
       " ('ommegang', 77.9354750420972),\n",
       " ('pigglys', 77.9354750420972),\n",
       " ('always', 72.72662897648594),\n",
       " ('spagghetti', 71.99999999999999),\n",
       " ('davilan', 71.99999999999999)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(w.items(), key=lambda x: x[1], reverse = True)[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 21.992014169692993 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "w = train_tfidf(list_dict)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for dict_ in list_dict:\n",
    "    if 'o_c' in dict_: \n",
    "        count +=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('docwe', -179.99999999999997),\n",
       " ('schweinhaxen', -179.99999999999997),\n",
       " ('ok', -153.25188439019598),\n",
       " ('lwqb9h3jz9wtk24lr', -143.99999999999997),\n",
       " ('anzq', -143.99999999999997),\n",
       " ('bland', -142.70265121062886),\n",
       " ('okay', -133.6185719765966),\n",
       " ('user_local_photos', -130.02503788885844),\n",
       " ('hanoi', -124.37021994944578),\n",
       " ('wai', -122.73859286707557),\n",
       " ('decent', -120.15699516554422),\n",
       " ('ellen', -119.12501808195492),\n",
       " ('sunup', -117.22987831642835),\n",
       " ('userid', -114.14296685874058),\n",
       " ('average', -110.47228516804344)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOP15 negative words\n",
    "sorted(w.items(), key=lambda x: x[1], reverse = False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('2kzmhgnq3zdl_oag6q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('grp', 186.011099519543),\n",
       " ('delicious', 152.20091708580398),\n",
       " ('amazing', 134.802818386992),\n",
       " ('kg', 132.48191460985473),\n",
       " ('great', 129.46785997892266),\n",
       " ('love', 128.0101510409685),\n",
       " ('biz_photos', 122.17244859527894),\n",
       " ('kfh', 122.008758540266),\n",
       " ('best', 116.0262100660396),\n",
       " ('merante', 112.40367605973644),\n",
       " ('maui', 105.57547116392335),\n",
       " ('blimpies', 104.36218527723078),\n",
       " ('perfect', 103.9242866715116),\n",
       " ('smth', 103.91396672278941),\n",
       " ('awesome', 97.6481313194764)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOP15 Positive words\n",
    "sorted(w.items(), key=lambda x: x[1], reverse = True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('pd2xo1wqnic9zxltvdilga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2 = \"hw2data_1/reviews_te.csv\"\n",
    "df_test = pd.read_csv(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_tfidf(df_test, w_tfidf, frequency):\n",
    "    dict_list_test = data_compression(df_test)\n",
    "    count = 0\n",
    "    wrong = 0\n",
    "    for x in dict_list_test:\n",
    "        for key, value in x.items():\n",
    "            if key != '*label*' and key != '*const*':\n",
    "                if key in frequency: x[key] = x[key] * math.log((len(dict_list_test) / frequency[key]), 10)\n",
    "        \n",
    "        count += 1\n",
    "        dot_product = 0\n",
    "        label = x['*label*']\n",
    "        for key, value in x.items():\n",
    "            if key in w and key != '*label*':\n",
    "                dot_product += w[key] * x[key]\n",
    "        if dot_product * label <= 0: wrong += 1 \n",
    "    return (count - wrong) / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8486233373526343\n",
      "--- 58.9832820892334 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(test_tfidf(df_test, w, frequency))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
