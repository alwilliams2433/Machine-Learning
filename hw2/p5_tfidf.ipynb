{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron Implementation with Tf-idf Data Representation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"hw2data_1/reviews_tr.csv\"\n",
    "df_train = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Representation: tf-idf\n",
    "# Use hashmap to compress the data\n",
    "def data_compression(df_train):\n",
    "    list_dict = []  # Contains training examples compressed with hashmap\n",
    "\n",
    "    for index, row in df_train.iterrows():\n",
    "        new_dict = {}\n",
    "        words = row['text'] + \"\"\n",
    "        words = words.split()\n",
    "        for word in words:\n",
    "            if word not in stopwords and len(word) < 18: # Stopwords & filter some invalid strings\n",
    "                if word in new_dict:\n",
    "                    new_dict[word] += 1\n",
    "                else:\n",
    "                    new_dict[word] = 1\n",
    "\n",
    "        if(row['label'] == 1):  # Attach the label\n",
    "            new_dict['*label*'] = 1\n",
    "        else: new_dict['*label*'] = -1\n",
    "\n",
    "        new_dict['*const*'] = 1   # Lifting\n",
    "        list_dict.append(new_dict)\n",
    "\n",
    "    return list_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_tfidf(list_dict):\n",
    "    w = {} \n",
    "    \n",
    "    # First pass\n",
    "    random.shuffle(list_dict)\n",
    "    for x in list_dict:\n",
    "        dot_product = 0\n",
    "        label = x['*label*']\n",
    "        for key, value in x.items():\n",
    "            if key != '*label*':\n",
    "                if key in w:\n",
    "                    dot_product += w[key] * x[key]\n",
    "        \n",
    "        if dot_product * label <= 0:           \n",
    "            for key, value in x.items():\n",
    "                if key != '*label*':\n",
    "                    if key in w:\n",
    "                        w[key] += label * x[key]\n",
    "                    else: w[key] = label * x[key]\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 145.77557611465454 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "list_dict = data_compression(df_train)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frequency = {}\n",
    "for x in list_dict:\n",
    "    for key, value in x.items():\n",
    "        if key in frequency:\n",
    "            frequency[key] += 1\n",
    "        else:\n",
    "            frequency[key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify feature vectors' values based on tf-idf\n",
    "for x in list_dict:\n",
    "    for key, value in x.items():\n",
    "        if key != '*label*' and key != '*const*':\n",
    "            x[key] = x[key] * math.log((len(list_dict) / frequency[key]), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 21.992014169692993 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "w = train_tfidf(list_dict)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for dict_ in list_dict:\n",
    "    if 'o_c' in dict_: \n",
    "        count +=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('doo', -148.99111265019025),\n",
       " ('harman', -89.99999999999999),\n",
       " ('keri', -83.65391881719037),\n",
       " ('mediocre', -82.43272464875668),\n",
       " ('worst', -81.81172372800869),\n",
       " ('meh', -72.94439239998083),\n",
       " ('ok', -72.12625708293135),\n",
       " ('overcooked', -70.13803863392015),\n",
       " ('bland', -64.50013572257738),\n",
       " ('salty', -64.12420336933748),\n",
       " ('potential', -64.0265266313933),\n",
       " ('underwhelmed', -63.73499166212217),\n",
       " ('inedible', -63.6136507805343),\n",
       " ('o_c', -59.99999999999999),\n",
       " ('2kzmhgnq3zdl_oag6q', -59.99999999999999)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOP15 negative words\n",
    "sorted(w.items(), key=lambda x: x[1], reverse = False)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bom', 92.04119982655924),\n",
       " ('zimm', 83.99999999999999),\n",
       " ('great', 82.99876161194948),\n",
       " ('delicious', 81.0586266229672),\n",
       " ('excellent', 75.59014627000612),\n",
       " ('stu', 75.53994238475472),\n",
       " ('amazing', 71.80004527157249),\n",
       " ('gem', 68.87245038457067),\n",
       " ('ftr', 67.84318117920506),\n",
       " ('best', 67.67807103838325),\n",
       " ('exceeded', 67.16646901630916),\n",
       " ('perfect', 66.69899477118987),\n",
       " ('perfection', 66.33219997298013),\n",
       " ('awesome', 62.26478012792374),\n",
       " ('love', 62.239691057049306)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TOP15 Positive words\n",
    "sorted(w.items(), key=lambda x: x[1], reverse = True)[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('pd2xo1wqnic9zxltvdilga')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path2 = \"hw2data_1/reviews_te.csv\"\n",
    "df_test = pd.read_csv(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_tfidf(df_test, w_tfidf, frequency):\n",
    "    dict_list_test = data_compression(df_test)\n",
    "    count = 0\n",
    "    wrong = 0\n",
    "    for x in dict_list_test:\n",
    "        for key, value in x.items():\n",
    "            if key != '*label*' and key != '*const*':\n",
    "                if key in frequency: x[key] = x[key] * math.log((len(dict_list_test) / frequency[key]), 10)\n",
    "        \n",
    "        count += 1\n",
    "        dot_product = 0\n",
    "        label = x['*label*']\n",
    "        for key, value in x.items():\n",
    "            if key in w and key != '*label*':\n",
    "                dot_product += w[key] * x[key]\n",
    "        if dot_product * label <= 0: wrong += 1 \n",
    "    return (count - wrong) / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8193251322933132\n",
      "--- 68.89674496650696 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(test_tfidf(df_test, w, frequency))\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
